#!/bin/bash

echo "=== Pipeline de Procesamiento de Datos - Tarea 2 SD ==="

# Esperar a que Hadoop estÃ© disponible
echo "â³ Esperando a que Hadoop estÃ© disponible..."
while ! hdfs dfsadmin -report &> /dev/null; do
    echo "   Hadoop no estÃ¡ listo, esperando 10 segundos..."
    sleep 10
done

echo "âœ… Hadoop estÃ¡ disponible"

# Crear directorios en HDFS si no existen
echo "ðŸ“ Creando directorios en HDFS..."
hdfs dfs -mkdir -p /input
hdfs dfs -mkdir -p /output

# Limpiar directorios de salida anteriores
echo "ðŸ§¹ Limpiando resultados anteriores..."
hdfs dfs -rm -r /output/* 2>/dev/null || true

# Copiar archivo CSV a HDFS
echo "ðŸ“¤ Copiando datos a HDFS..."
if [ -f "/input/waze_incidents.csv" ]; then
    hdfs dfs -put /input/waze_incidents.csv /input/
    echo "âœ… Archivo CSV copiado a HDFS"
else
    echo "âŒ Error: No se encontrÃ³ el archivo /input/waze_incidents.csv"
    echo "   AsegÃºrate de ejecutar primero el exportador de datos"
    exit 1
fi

# Verificar que el archivo estÃ© en HDFS
echo "ðŸ“‹ Verificando archivo en HDFS..."
hdfs dfs -ls /input/

# Ejecutar script de Pig
echo "ðŸ· Ejecutando script de Pig..."
pig -f /scripts/process_incidents.pig

# Verificar resultados
echo "ðŸ“Š Verificando resultados generados..."
echo "Archivos de salida en HDFS:"
hdfs dfs -ls /output/

# Copiar resultados a sistema local para revisiÃ³n
echo "ðŸ“¥ Copiando resultados al sistema local..."
hdfs dfs -get /output/* /output/ 2>/dev/null || true

echo "âœ… Pipeline completado!"
echo "ðŸ“ Los resultados estÃ¡n disponibles en:"
echo "   - HDFS: /output/"
echo "   - Local: /output/"

# Mostrar primeras lÃ­neas de cada resultado
echo ""
echo "=== PREVIEW DE RESULTADOS ==="
for dir in /output/*/; do
    if [ -d "$dir" ]; then
        echo ""
        echo "--- $(basename "$dir") ---"
        find "$dir" -name "part-*" -type f | head -1 | xargs head -10 2>/dev/null || echo "No se pudieron leer los datos"
    fi
done